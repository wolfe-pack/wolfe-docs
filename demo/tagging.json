{
  "name" : "Sequence Tagging with CRFs",
  "cells" : [ {
    "id" : 0,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "import ml.wolfe.examples.TaggingExample._\n\nval doc = TokenSplitter(SentenceSplitter(\n\"John Denver is a Songwriter. Denver has produced many records\"))\nval example = doc.tokens.map(_.word)\n\nval words = example.distinct\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\n\nBratRenderer.bratIE(doc)",
      "extraFields" : {
        "aggregatedCells" : "[]"
      },
      "outputFormat" : "<div class=\"string-result\"><div id=\"brat887260853\" class=\"hasSVG\" style=\"display: block; height: 35px;\"><svg version=\"1.1\" viewBox=\"0 0 650 35\" class=\"bratsvg\" style=\"width: 650px; height: 35px;\"><!-- document: undefined/undefined --><defs><filter id=\"Gaussian_Blur\"><fegaussianblur in=\"SourceGraphic\" stddeviation=\"2\"></fegaussianblur></filter><marker id=\"drag_arrow\" refX=\"5\" refY=\"2.5\" markerWidth=\"5\" markerHeight=\"5\" orient=\"auto\" markerUnits=\"strokeWidth\" class=\"drag_fill\"><polyline points=\"0,0 5,2.5 0,5 0.2,2.5\"></polyline></marker></defs><g class=\"background\"><rect x=\"0\" y=\"3.5\" width=\"650\" height=\"16.5\" class=\"background0\"></rect><rect x=\"0\" y=\"20\" width=\"650\" height=\"16.5\" class=\"background1\"></rect></g><g class=\"glow\"></g><g class=\"highlight\"></g><g class=\"text\"><text x=\"0\" y=\"0\"><tspan x=\"24\" y=\"14.5\" data-chunk-id=\"0\" class=\"brat-text\">John </tspan><tspan x=\"54.021484375\" y=\"14.5\" data-chunk-id=\"1\" class=\"brat-text\">Denver </tspan><tspan x=\"96.705078125\" y=\"14.5\" data-chunk-id=\"2\" class=\"brat-text\">is </tspan><tspan x=\"109.37109375\" y=\"14.5\" data-chunk-id=\"3\" class=\"brat-text\">a </tspan><tspan x=\"120.044921875\" y=\"14.5\" data-chunk-id=\"4\" class=\"brat-text\">Songwriter</tspan><tspan x=\"177.40234375\" y=\"14.5\" data-chunk-id=\"5\" class=\"brat-text\">. </tspan></text><text x=\"0\" y=\"0\"><tspan x=\"24\" y=\"31\" data-chunk-id=\"6\" class=\"brat-text\">Denver </tspan><tspan x=\"66.68359375\" y=\"31\" data-chunk-id=\"7\" class=\"brat-text\">has </tspan><tspan x=\"90.03125\" y=\"31\" data-chunk-id=\"8\" class=\"brat-text\">produced </tspan><tspan x=\"144.0703125\" y=\"31\" data-chunk-id=\"9\" class=\"brat-text\">many </tspan><tspan x=\"177.4140625\" y=\"31\" data-chunk-id=\"10\" class=\"brat-text\">records</tspan></text></g><g transform=\"translate(0, 14)\"><g></g><g transform=\"translate(24, 0)\"><g></g></g><g transform=\"translate(54.021484375, 0)\"><g></g></g><g transform=\"translate(96.705078125, 0)\"><g></g></g><g transform=\"translate(109.37109375, 0)\"><g></g></g><g transform=\"translate(120.044921875, 0)\"><g></g></g><g transform=\"translate(177.40234375, 0)\"><g></g></g><g class=\"arcs\"></g></g><g transform=\"translate(0, 31)\"><g></g><g transform=\"translate(24, 0)\"><g></g></g><g transform=\"translate(66.68359375, 0)\"><g></g></g><g transform=\"translate(90.03125, 0)\"><g></g></g><g transform=\"translate(144.0703125, 0)\"><g></g></g><g transform=\"translate(177.4140625, 0)\"><g></g></g><g class=\"arcs\"></g></g><g class=\"sentnum\"><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#undefined?focus=sent~1\"><text x=\"18\" y=\"14.5\" data-sent=\"1\">1</text></a><a xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#undefined?focus=sent~2\"><text x=\"18\" y=\"31\" data-sent=\"2\">2</text></a><path d=\"M20,0L20,35\"></path></g></svg></div>\n\n <link rel=\"stylesheet\" type=\"text/css\" href=\"/assets/javascripts/brat/style-vis.css\">\n <link rel=\"stylesheet\" type=\"text/css\" href=\"/assets/stylesheets/wolfe-brat.css\">\n\n\n<script type=\"text/javascript\">\n        var bratLocation;\n\n             console.log(\"embedBrat\");\n             if (typeof bratLocation === 'undefined') {\n                bratLocation = \"/assets/javascripts/brat\";\n                head.js(\n                    // External libraries\n                    bratLocation + '/client/lib/jquery.min.js',\n                    bratLocation + '/client/lib/jquery.svg.min.js',\n                    bratLocation + '/client/lib/jquery.svgdom.min.js',\n\n                    // brat helper modules\n                    bratLocation + '/client/src/configuration.js',\n                    bratLocation + '/client/src/util.js',\n                    bratLocation + '/client/src/annotation_log.js',\n                    bratLocation + '/client/lib/webfont.js',\n\n                    // brat modules\n                    bratLocation + '/client/src/dispatcher.js',\n                    bratLocation + '/client/src/url_monitor.js',\n                    bratLocation + '/client/src/visualizer.js'\n                 );\n                 console.log(\"head.js called\");\n             }\n\n             head.ready(function() {\n                console.log(\"Head is ready\");\n\n                var collData =\n{\n    entity_types: [  ]\n}\n      ;\n\n                var docData =\n{\n    // Our text of choice\n    text     : \"John Denver is a Songwriter. Denver has produced many records\",\n    // The entities entry holds all entity annotations\n    entities : [\n        /* Format: [{ID}, {TYPE}, [[{START}, {END}]]]\n            note that range of the offsets are [{START},{END}) */\n\n    ],\n    sentence_offsets: [[0,28],[29,61]],\n    token_offsets: [[0,4],[5,11],[12,14],[15,16],[17,27],[27,28],[29,35],[36,39],[40,48],[49,53],[54,61]]\n}\n      ;\n\n                Util.embed(\n                    // id of the div element where brat should embed the visualisations\n                    'brat887260853',\n                    // object containing collection data\n                    collData,\n                    // object containing document data\n                    docData,\n                    // Array containing locations of the visualisation fonts\n\n[\n    '/assets/javascripts/brat' + '/static/fonts/PT_Sans-Caption-Web-Regular.ttf',\n    '/assets/javascripts/brat' + '/static/fonts/Liberation_Sans-Regular.ttf'\n]\n\n                    );\n            });\n\n\n\n    </script></div>"
    }
  }, {
    "id" : 1,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Define the domains or inputs, outputs and parameters\nval maxLength = 15\nimplicit val Words = words.toDom withOOV \"[OOV]\"\nimplicit val Tags = tags.toDom\nimplicit val Y = Seqs(Tags, 0, maxLength)\nimplicit val Weights = Vectors(dim = 1000)\n\nimplicit val index = new SimpleIndex() // For indexing Weights vectors",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\"]"
      },
      "outputFormat" : "<div class=\"text-center\"><i class=\"fa fa-refresh fa-spin fa-lg\"></i></div>"
    }
  }, {
    "id" : 2,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Define a score function\n\nval firstName = Set(\"John\", \"Jack\")\nval lastName = Set(\"Denver\")\nval location = Set(\"Denver\", \"Dallas\")\nval punct     = Set(\",\", \".\", \"?\", \";\")\ndef lowercase(w: Words.Value) = w.head.isLower\n\ndef model(w: Weights.Term, x: Seq[Words.Value])(y: Y.Term) = {\n    sum(0 until x.length) { i => \n        (w dot feature('bias, y(i))) +\n        (w dot feature('word, y(i) -> x(i).toConst)) +\n        (w dot feature('firstName, I(firstName(x(i)).toConst), y(i))) +\n        (w dot feature('lastName, I(lastName(x(i)).toConst), y(i))) +\n        (w dot feature('location, I(location(x(i)).toConst), y(i)))\n    } + sum(0 until x.length - 1) { i => \n        w dot feature('pair, y(i) -> y(i + 1))\n    }\n} subjectTo (y.length === x.length) // Require one tag per word\n\nval wStar = preloadWeights()\n\n// An tag sequence that is too long for the example\nval longSequence = IndexedSeq.fill(2)('O)\nmodel(Weights.Const(wStar), example.take(2))(Y.Const(longSequence))",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\",\"// Define the domains or inputs, outputs and parameters\\nval maxLength = 15\\nimplicit val Words = words.toDom withOOV \\\"[OOV]\\\"\\nimplicit val Tags = tags.toDom\\nimplicit val Y = Seqs(Tags, 0, maxLength)\\nimplicit val Weights = Vectors(dim = 1000)\\n\\nimplicit val index = new SimpleIndex() // For indexing Weights vectors\"]"
      },
      "outputFormat" : ""
    }
  }, {
    "id" : 3,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// A tag sequence of the correct length\nval betterSequence = IndexedSeq.fill(11)('O)\nmodel(Weights.Const(wStar), example)(Y.Const(betterSequence)).eval()",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\",\"// Define the domains or inputs, outputs and parameters\\nval maxLength = 15\\nimplicit val Words = words.toDom withOOV \\\"[OOV]\\\"\\nimplicit val Tags = tags.toDom\\nimplicit val Y = Seqs(Tags, 0, maxLength)\\nimplicit val Weights = Vectors(dim = 1000)\\n\\nimplicit val index = new SimpleIndex() // For indexing Weights vectors\",\"// Define a score function\\n\\nval firstName = Set(\\\"John\\\", \\\"Jack\\\")\\nval lastName = Set(\\\"Denver\\\")\\nval location = Set(\\\"Denver\\\", \\\"Dallas\\\")\\nval punct     = Set(\\\",\\\", \\\".\\\", \\\"?\\\", \\\";\\\")\\ndef lowercase(w: Words.Value) = w.head.isLower\\n\\ndef model(w: Weights.Term, x: Seq[Words.Value])(y: Y.Term) = {\\n    sum(0 until x.length) { i => \\n        (w dot feature('bias, y(i))) +\\n        (w dot feature('word, y(i) -> x(i).toConst)) +\\n        (w dot feature('firstName, I(firstName(x(i)).toConst), y(i))) +\\n        (w dot feature('lastName, I(lastName(x(i)).toConst), y(i))) +\\n        (w dot feature('location, I(location(x(i)).toConst), y(i)))\\n    } + sum(0 until x.length - 1) { i => \\n        w dot feature('pair, y(i) -> y(i + 1))\\n    }\\n} subjectTo (y.length === x.length) // Require one tag per word\\n\\nval wStar = preloadWeights()\\n\\n// An tag sequence that is too long for the example\\nval longSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(longSequence)).eval()\"]"
      },
      "outputFormat" : ""
    }
  }, {
    "id" : 4,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Find the optimal tag sequence for this example, by maxProduct\nimplicit val maxProductParams = BPParameters(iterations = 1)\n\ndef predict(x: Seq[Words.Value]) = argmax(Y) {\n    model(Weights.Const(wStar), x)\n} by maxProduct\nval result = predict(example).evalResult()\nBratRenderer.bratIE(doc withEntityTags result)//.toTaggedText",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\",\"// Define the domains or inputs, outputs and parameters\\nval maxLength = 15\\nimplicit val Words = words.toDom withOOV \\\"[OOV]\\\"\\nimplicit val Tags = tags.toDom\\nimplicit val Y = Seqs(Tags, 0, maxLength)\\nimplicit val Weights = Vectors(dim = 1000)\\n\\nimplicit val index = new SimpleIndex() // For indexing Weights vectors\",\"// Define a score function\\n\\nval firstName = Set(\\\"John\\\", \\\"Jack\\\")\\nval lastName = Set(\\\"Denver\\\")\\nval location = Set(\\\"Denver\\\", \\\"Dallas\\\")\\nval punct     = Set(\\\",\\\", \\\".\\\", \\\"?\\\", \\\";\\\")\\ndef lowercase(w: Words.Value) = w.head.isLower\\n\\ndef model(w: Weights.Term, x: Seq[Words.Value])(y: Y.Term) = {\\n    sum(0 until x.length) { i => \\n        (w dot feature('bias, y(i))) +\\n        (w dot feature('word, y(i) -> x(i).toConst)) +\\n        (w dot feature('firstName, I(firstName(x(i)).toConst), y(i))) +\\n        (w dot feature('lastName, I(lastName(x(i)).toConst), y(i))) +\\n        (w dot feature('location, I(location(x(i)).toConst), y(i)))\\n    } + sum(0 until x.length - 1) { i => \\n        w dot feature('pair, y(i) -> y(i + 1))\\n    }\\n} subjectTo (y.length === x.length) // Require one tag per word\\n\\nval wStar = preloadWeights()\\n\\n// An tag sequence that is too long for the example\\nval longSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(longSequence)).eval()\",\"// A tag sequence of the correct length\\nval betterSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(betterSequence)).eval()\"]"
      },
      "outputFormat" : ""
    }
  }, {
    "id" : 5,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// The factor graph which was used to perform inference\nresult.factorGraphs.head",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\",\"// Define the domains or inputs, outputs and parameters\\nval maxLength = 15\\nimplicit val Words = words.toDom withOOV \\\"[OOV]\\\"\\nimplicit val Tags = tags.toDom\\nimplicit val Y = Seqs(Tags, 0, maxLength)\\nimplicit val Weights = Vectors(dim = 1000)\\n\\nimplicit val index = new SimpleIndex() // For indexing Weights vectors\",\"// Define a score function\\n\\nval firstName = Set(\\\"John\\\", \\\"Jack\\\")\\nval lastName = Set(\\\"Denver\\\")\\nval location = Set(\\\"Denver\\\", \\\"Dallas\\\")\\nval punct     = Set(\\\",\\\", \\\".\\\", \\\"?\\\", \\\";\\\")\\ndef lowercase(w: Words.Value) = w.head.isLower\\n\\ndef model(w: Weights.Term, x: Seq[Words.Value])(y: Y.Term) = {\\n    sum(0 until x.length) { i => \\n        (w dot feature('bias, y(i))) +\\n        (w dot feature('word, y(i) -> x(i).toConst)) +\\n        (w dot feature('firstName, I(firstName(x(i)).toConst), y(i))) +\\n        (w dot feature('lastName, I(lastName(x(i)).toConst), y(i))) +\\n        (w dot feature('location, I(location(x(i)).toConst), y(i)))\\n    } + sum(0 until x.length - 1) { i => \\n        w dot feature('pair, y(i) -> y(i + 1))\\n    }\\n} subjectTo (y.length === x.length) // Require one tag per word\\n\\nval wStar = preloadWeights()\\n\\n// An tag sequence that is too long for the example\\nval longSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(longSequence)).eval()\",\"// A tag sequence of the correct length\\nval betterSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(betterSequence)).eval()\",\"// Find the optimal tag sequence for this example, by maxProduct\\nimplicit val maxProductParams = BPParameters(iterations = 1)\\n\\ndef predict(x: Seq[Words.Value]) = argmax(Y) {\\n    model(Weights.Const(wStar), x)\\n} by maxProduct\\nval result = predict(example).evalResult()\\nBratRenderer.bratIE(doc withEntityTags result)//.toTaggedText\"]"
      },
      "outputFormat" : ""
    }
  }, {
    "id" : 6,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Build a new model with factors between matching words\ndef matchingPairs(x: Seq[Words.Value]) =\n    for (j <- 0 until x.length; i <- 0 until j; if x(i) != \".\" && x(i) == x(j)) yield (i, j)\n    \ndef skipModel(w: Weights.Term,x: Seq[Words.Value])(y: Y.Term) = {\n    def matches = matchingPairs(x)\n    model(w,x)(y) + \n    sum(0 until matches.length) { i => \n        w dot feature('match, y(matches(i)._1) -> y(matches(i)._2))\n    }\n}\n\ndef predict2(x: Seq[Words.Value]) = argmax(Y) {\n    skipModel(Weights.Const(wStar), x)\n} by maxProduct\n\nval result2 = predict2(example).evalResult()\nBratRenderer.bratIE(doc withEntityTags result2)",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\",\"// Define the domains or inputs, outputs and parameters\\nval maxLength = 15\\nimplicit val Words = words.toDom withOOV \\\"[OOV]\\\"\\nimplicit val Tags = tags.toDom\\nimplicit val Y = Seqs(Tags, 0, maxLength)\\nimplicit val Weights = Vectors(dim = 1000)\\n\\nimplicit val index = new SimpleIndex() // For indexing Weights vectors\",\"// Define a score function\\n\\nval firstName = Set(\\\"John\\\", \\\"Jack\\\")\\nval lastName = Set(\\\"Denver\\\")\\nval location = Set(\\\"Denver\\\", \\\"Dallas\\\")\\nval punct     = Set(\\\",\\\", \\\".\\\", \\\"?\\\", \\\";\\\")\\ndef lowercase(w: Words.Value) = w.head.isLower\\n\\ndef model(w: Weights.Term, x: Seq[Words.Value])(y: Y.Term) = {\\n    sum(0 until x.length) { i => \\n        (w dot feature('bias, y(i))) +\\n        (w dot feature('word, y(i) -> x(i).toConst)) +\\n        (w dot feature('firstName, I(firstName(x(i)).toConst), y(i))) +\\n        (w dot feature('lastName, I(lastName(x(i)).toConst), y(i))) +\\n        (w dot feature('location, I(location(x(i)).toConst), y(i)))\\n    } + sum(0 until x.length - 1) { i => \\n        w dot feature('pair, y(i) -> y(i + 1))\\n    }\\n} subjectTo (y.length === x.length) // Require one tag per word\\n\\nval wStar = preloadWeights()\\n\\n// An tag sequence that is too long for the example\\nval longSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(longSequence)).eval()\",\"// A tag sequence of the correct length\\nval betterSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(betterSequence)).eval()\",\"// Find the optimal tag sequence for this example, by maxProduct\\nimplicit val maxProductParams = BPParameters(iterations = 1)\\n\\ndef predict(x: Seq[Words.Value]) = argmax(Y) {\\n    model(Weights.Const(wStar), x)\\n} by maxProduct\\nval result = predict(example).evalResult()\\nBratRenderer.bratIE(doc withEntityTags result)//.toTaggedText\",\"// The factor graph which was used to perform inference\\nresult.factorGraphs.head\"]"
      },
      "outputFormat" : ""
    }
  }, {
    "id" : 7,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "result2.factorGraphs.head",
      "extraFields" : {
        "aggregatedCells" : "[\"import ml.wolfe.examples.TaggingExample._\\n\\nval doc = TokenSplitter(SentenceSplitter(\\n\\\"John Denver is a Songwriter. Denver has produced many records\\\"))\\nval example = doc.tokens.map(_.word)\\n\\nval words = example.distinct\\nval tags = Seq('O, 'B_LOC, 'I_LOC, 'B_PER, 'I_PER)\\n\\nBratRenderer.bratIE(doc)\",\"// Define the domains or inputs, outputs and parameters\\nval maxLength = 15\\nimplicit val Words = words.toDom withOOV \\\"[OOV]\\\"\\nimplicit val Tags = tags.toDom\\nimplicit val Y = Seqs(Tags, 0, maxLength)\\nimplicit val Weights = Vectors(dim = 1000)\\n\\nimplicit val index = new SimpleIndex() // For indexing Weights vectors\",\"// Define a score function\\n\\nval firstName = Set(\\\"John\\\", \\\"Jack\\\")\\nval lastName = Set(\\\"Denver\\\")\\nval location = Set(\\\"Denver\\\", \\\"Dallas\\\")\\nval punct     = Set(\\\",\\\", \\\".\\\", \\\"?\\\", \\\";\\\")\\ndef lowercase(w: Words.Value) = w.head.isLower\\n\\ndef model(w: Weights.Term, x: Seq[Words.Value])(y: Y.Term) = {\\n    sum(0 until x.length) { i => \\n        (w dot feature('bias, y(i))) +\\n        (w dot feature('word, y(i) -> x(i).toConst)) +\\n        (w dot feature('firstName, I(firstName(x(i)).toConst), y(i))) +\\n        (w dot feature('lastName, I(lastName(x(i)).toConst), y(i))) +\\n        (w dot feature('location, I(location(x(i)).toConst), y(i)))\\n    } + sum(0 until x.length - 1) { i => \\n        w dot feature('pair, y(i) -> y(i + 1))\\n    }\\n} subjectTo (y.length === x.length) // Require one tag per word\\n\\nval wStar = preloadWeights()\\n\\n// An tag sequence that is too long for the example\\nval longSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(longSequence)).eval()\",\"// A tag sequence of the correct length\\nval betterSequence = IndexedSeq.fill(11)('O)\\nmodel(Weights.Const(wStar), example)(Y.Const(betterSequence)).eval()\",\"// Find the optimal tag sequence for this example, by maxProduct\\nimplicit val maxProductParams = BPParameters(iterations = 1)\\n\\ndef predict(x: Seq[Words.Value]) = argmax(Y) {\\n    model(Weights.Const(wStar), x)\\n} by maxProduct\\nval result = predict(example).evalResult()\\nBratRenderer.bratIE(doc withEntityTags result)//.toTaggedText\",\"// The factor graph which was used to perform inference\\nresult.factorGraphs.head\",\"// Build a new model with factors between matching words\\ndef matchingPairs(x: Seq[Words.Value]) =\\n    for (j <- 0 until x.length; i <- 0 until j; if x(i) != \\\".\\\" && x(i) == x(j)) yield (i, j)\\n    \\ndef skipModel(w: Weights.Term,x: Seq[Words.Value])(y: Y.Term) = {\\n    def matches = matchingPairs(x)\\n    model(w,x)(y) + \\n    sum(0 until matches.length) { i => \\n        w dot feature('match, y(matches(i)._1) -> y(matches(i)._2))\\n    }\\n}\\n\\ndef predict2(x: Seq[Words.Value]) = argmax(Y) {\\n    skipModel(Weights.Const(wStar), x)\\n} by maxProduct\\n\\nval result2 = predict2(example).evalResult()\\nBratRenderer.bratIE(doc withEntityTags result2)\"]"
      },
      "outputFormat" : ""
    }
  } ],
  "config" : { }
}
