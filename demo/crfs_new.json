{
  "name" : "Chunking with CRFs",
  "cells" : [ {
    "id" : 0,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Load dataset from the CoNLL-2000 Chunking Shared Task\nval train = CoNLL2000.train.take(2).toSeq\nval labels = train.flatMap(_._2).distinct\nval words = train.flatMap(_._1).distinct\nwords.take(5)",
      "extraFields" : {
        "aggregatedCells" : "[]"
      },
      "outputFormat" : "<div class=\"string-result\"><div class=\"asIterable List\"><span class=\"typeName\">List</span>\n<ol start=\"0\" class=\"fields\">\n  <li class=\"fieldValue\"><span class=\"asString String\">Confidence</span></li>\n  <li class=\"fieldValue\"><span class=\"asString String\">in</span></li>\n  <li class=\"fieldValue\"><span class=\"asString String\">the</span></li>\n  <li class=\"fieldValue\"><span class=\"asString String\">pound</span></li>\n  <li class=\"fieldValue\"><span class=\"asString String\">is</span></li>\n</ol>\n</div></div>"
    }
  }, {
    "id" : 1,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Define the domain of inputs, outputs and parameters\nval maxLength = train.map(_._2.length).max\nimplicit val Inputs = Seqs(words.toDom withOOV \"[OOV]\", 0, maxLength)\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\nimplicit val Instances = Pairs(Inputs, Outputs)\nimplicit val Thetas = Vectors(dim = 20000)",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"asString String\">ml.wolfe.term.VectorDom@66304338</span></div>"
    }
  }, {
    "id" : 2,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Define the model\nimplicit val index = new SimpleIndex()\nimplicit val maxProductParams = MaxProductParameters(iterations = 1)\n\ndef biasTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) =\n    sum(0 until x.length)(i => t dot feature('bias, y(i)))\n    \ndef wordTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \n    sum(0 until x.length)(i => t dot feature('word, x(i), y(i)))\n    \ndef pairTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \n    sum(0 until x.length - 1)(i => t dot feature('pair, y(i), y(i+1)))\n    \ndef model(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y)\n} subjectTo (y.length === x.length) argmaxBy maxProduct",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\",\"// Define the domain of inputs, outputs and parameters\\nval maxLength = train.map(_._2.length).max\\nimplicit val Inputs = Seqs(words.toDom withOOV \\\"[OOV]\\\", 0, maxLength)\\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\\nimplicit val Instances = Pairs(Inputs, Outputs)\\nimplicit val Thetas = Vectors(dim = 20000)\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"label label-danger\">Error!</span>\n<pre class=\"error\"><console>:71: error: not found: value MaxProductParameters\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                       ^\n<console>:71: error: not found: value iterations\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                                            ^\n<console>:84: error: could not find implicit value for parameter params: ml.wolfe.term.BPParameters\n       } subjectTo (y.length === x.length) argmaxBy maxProduct\n                                                    ^\n</console></console></console></pre></div>"
    }
  }, {
    "id" : 3,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Learn the parameters with AdaGrad\nimplicit val adagradParams = AdaGradParameters(epochs = 1, learningRate = 0.1)\n\nval thetaStar = learn(Thetas){ t =>\n    perceptron(train.toConst)(Outputs)(model(t))\n} using adaGrad\nthetaStar.toIndexedString",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\",\"// Define the domain of inputs, outputs and parameters\\nval maxLength = train.map(_._2.length).max\\nimplicit val Inputs = Seqs(words.toDom withOOV \\\"[OOV]\\\", 0, maxLength)\\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\\nimplicit val Instances = Pairs(Inputs, Outputs)\\nimplicit val Thetas = Vectors(dim = 20000)\",\"// Define the model\\nimplicit val index = new SimpleIndex()\\nimplicit val maxProductParams = MaxProductParameters(iterations = 1)\\n\\ndef biasTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) =\\n    sum(0 until x.length)(i => t dot feature('bias, y(i)))\\n    \\ndef wordTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length)(i => t dot feature('word, x(i), y(i)))\\n    \\ndef pairTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length - 1)(i => t dot feature('pair, y(i), y(i+1)))\\n    \\ndef model(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y)\\n} subjectTo (y.length === x.length) argmaxBy maxProduct\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"label label-danger\">Error!</span>\n<pre class=\"error\"><console>:71: error: not found: value MaxProductParameters\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                       ^\n<console>:71: error: not found: value iterations\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                                            ^\n<console>:84: error: could not find implicit value for parameter params: ml.wolfe.term.BPParameters\n       } subjectTo (y.length === x.length) argmaxBy maxProduct\n                                                    ^\n</console></console></console></pre></div>"
    }
  }, {
    "id" : 4,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// Predict the labels for an unseen test example\ndef predict(x:Inputs.Value) = argmax(Outputs){\n    model(thetaStar.toConst)(Inputs.Const(x))\n}\nval test = IndexedSeq(\"This\", \"is\", \"a\", \"test\")\nval result = predict(test).evalResult()",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\",\"// Define the domain of inputs, outputs and parameters\\nval maxLength = train.map(_._2.length).max\\nimplicit val Inputs = Seqs(words.toDom withOOV \\\"[OOV]\\\", 0, maxLength)\\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\\nimplicit val Instances = Pairs(Inputs, Outputs)\\nimplicit val Thetas = Vectors(dim = 20000)\",\"// Define the model\\nimplicit val index = new SimpleIndex()\\nimplicit val maxProductParams = MaxProductParameters(iterations = 1)\\n\\ndef biasTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) =\\n    sum(0 until x.length)(i => t dot feature('bias, y(i)))\\n    \\ndef wordTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length)(i => t dot feature('word, x(i), y(i)))\\n    \\ndef pairTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length - 1)(i => t dot feature('pair, y(i), y(i+1)))\\n    \\ndef model(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y)\\n} subjectTo (y.length === x.length) argmaxBy maxProduct\",\"// Learn the parameters with AdaGrad\\nimplicit val adagradParams = AdaGradParameters(epochs = 1, learningRate = 0.1)\\n\\nval thetaStar = learn(Thetas){ t =>\\n    perceptron(train.toConst)(Outputs)(model(t))\\n} using adaGrad\\nthetaStar.toIndexedString\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"label label-danger\">Error!</span>\n<pre class=\"error\"><console>:71: error: not found: value MaxProductParameters\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                       ^\n<console>:71: error: not found: value iterations\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                                            ^\n<console>:84: error: could not find implicit value for parameter params: ml.wolfe.term.BPParameters\n       } subjectTo (y.length === x.length) argmaxBy maxProduct\n                                                    ^\n</console></console></console></pre></div>"
    }
  }, {
    "id" : 5,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "// The factor graph used in inference\nresult.factorGraphs.head",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\",\"// Define the domain of inputs, outputs and parameters\\nval maxLength = train.map(_._2.length).max\\nimplicit val Inputs = Seqs(words.toDom withOOV \\\"[OOV]\\\", 0, maxLength)\\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\\nimplicit val Instances = Pairs(Inputs, Outputs)\\nimplicit val Thetas = Vectors(dim = 20000)\",\"// Define the model\\nimplicit val index = new SimpleIndex()\\nimplicit val maxProductParams = MaxProductParameters(iterations = 1)\\n\\ndef biasTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) =\\n    sum(0 until x.length)(i => t dot feature('bias, y(i)))\\n    \\ndef wordTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length)(i => t dot feature('word, x(i), y(i)))\\n    \\ndef pairTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length - 1)(i => t dot feature('pair, y(i), y(i+1)))\\n    \\ndef model(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y)\\n} subjectTo (y.length === x.length) argmaxBy maxProduct\",\"// Learn the parameters with AdaGrad\\nimplicit val adagradParams = AdaGradParameters(epochs = 1, learningRate = 0.1)\\n\\nval thetaStar = learn(Thetas){ t =>\\n    perceptron(train.toConst)(Outputs)(model(t))\\n} using adaGrad\\nthetaStar.toIndexedString\",\"// Predict the labels for an unseen test example\\ndef predict(x:Inputs.Value) = argmax(Outputs){\\n    model(thetaStar.toConst)(Inputs.Const(x))\\n}\\nval test = IndexedSeq(\\\"This\\\", \\\"is\\\", \\\"a\\\", \\\"test\\\")\\nval result = predict(test).evalResult()\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"label label-danger\">Error!</span>\n<pre class=\"error\"><console>:71: error: not found: value MaxProductParameters\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                       ^\n<console>:71: error: not found: value iterations\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                                            ^\n<console>:84: error: could not find implicit value for parameter params: ml.wolfe.term.BPParameters\n       } subjectTo (y.length === x.length) argmaxBy maxProduct\n                                                    ^\n</console></console></console></pre></div>"
    }
  }, {
    "id" : 6,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "//Add skip-chain features to the model\ndef skipTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \n    sum(0 until x.length - 2)(i => t dot feature('skip, y(i), y(i+2)))\n\ndef newModel(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y) + skipTerms(t)(x, y)\n} subjectTo (y.length === x.length) argmaxBy maxProduct\n\nval newTheta = learn(Thetas){ t => \n    perceptron(train.toConst)(Outputs)(newModel(t))\n} using adaGrad\n\nval newResult = argmax(Outputs){ newModel(thetaStar.toConst)(Inputs.Const(test))}.evalResult()\n",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\",\"// Define the domain of inputs, outputs and parameters\\nval maxLength = train.map(_._2.length).max\\nimplicit val Inputs = Seqs(words.toDom withOOV \\\"[OOV]\\\", 0, maxLength)\\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\\nimplicit val Instances = Pairs(Inputs, Outputs)\\nimplicit val Thetas = Vectors(dim = 20000)\",\"// Define the model\\nimplicit val index = new SimpleIndex()\\nimplicit val maxProductParams = MaxProductParameters(iterations = 1)\\n\\ndef biasTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) =\\n    sum(0 until x.length)(i => t dot feature('bias, y(i)))\\n    \\ndef wordTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length)(i => t dot feature('word, x(i), y(i)))\\n    \\ndef pairTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length - 1)(i => t dot feature('pair, y(i), y(i+1)))\\n    \\ndef model(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y)\\n} subjectTo (y.length === x.length) argmaxBy maxProduct\",\"// Learn the parameters with AdaGrad\\nimplicit val adagradParams = AdaGradParameters(epochs = 1, learningRate = 0.1)\\n\\nval thetaStar = learn(Thetas){ t =>\\n    perceptron(train.toConst)(Outputs)(model(t))\\n} using adaGrad\\nthetaStar.toIndexedString\",\"// Predict the labels for an unseen test example\\ndef predict(x:Inputs.Value) = argmax(Outputs){\\n    model(thetaStar.toConst)(Inputs.Const(x))\\n}\\nval test = IndexedSeq(\\\"This\\\", \\\"is\\\", \\\"a\\\", \\\"test\\\")\\nval result = predict(test).evalResult()\",\"// The factor graph used in inference\\nresult.factorGraphs.head\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"label label-danger\">Error!</span>\n<pre class=\"error\"><console>:71: error: not found: value MaxProductParameters\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                       ^\n<console>:71: error: not found: value iterations\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                                            ^\n<console>:84: error: could not find implicit value for parameter params: ml.wolfe.term.BPParameters\n       } subjectTo (y.length === x.length) argmaxBy maxProduct\n                                                    ^\n</console></console></console></pre></div>"
    }
  }, {
    "id" : 7,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "newResult.factorGraphs.head",
      "extraFields" : {
        "aggregatedCells" : "[\"// Load dataset from the CoNLL-2000 Chunking Shared Task\\nval train = CoNLL2000.train.take(2).toSeq\\nval labels = train.flatMap(_._2).distinct\\nval words = train.flatMap(_._1).distinct\\nwords.take(5)\",\"// Define the domain of inputs, outputs and parameters\\nval maxLength = train.map(_._2.length).max\\nimplicit val Inputs = Seqs(words.toDom withOOV \\\"[OOV]\\\", 0, maxLength)\\nimplicit val Outputs = Seqs(labels.toDom, 0, maxLength)\\nimplicit val Instances = Pairs(Inputs, Outputs)\\nimplicit val Thetas = Vectors(dim = 20000)\",\"// Define the model\\nimplicit val index = new SimpleIndex()\\nimplicit val maxProductParams = MaxProductParameters(iterations = 1)\\n\\ndef biasTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) =\\n    sum(0 until x.length)(i => t dot feature('bias, y(i)))\\n    \\ndef wordTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length)(i => t dot feature('word, x(i), y(i)))\\n    \\ndef pairTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length - 1)(i => t dot feature('pair, y(i), y(i+1)))\\n    \\ndef model(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y)\\n} subjectTo (y.length === x.length) argmaxBy maxProduct\",\"// Learn the parameters with AdaGrad\\nimplicit val adagradParams = AdaGradParameters(epochs = 1, learningRate = 0.1)\\n\\nval thetaStar = learn(Thetas){ t =>\\n    perceptron(train.toConst)(Outputs)(model(t))\\n} using adaGrad\\nthetaStar.toIndexedString\",\"// Predict the labels for an unseen test example\\ndef predict(x:Inputs.Value) = argmax(Outputs){\\n    model(thetaStar.toConst)(Inputs.Const(x))\\n}\\nval test = IndexedSeq(\\\"This\\\", \\\"is\\\", \\\"a\\\", \\\"test\\\")\\nval result = predict(test).evalResult()\",\"// The factor graph used in inference\\nresult.factorGraphs.head\",\"//Add skip-chain features to the model\\ndef skipTerms(t: Thetas.Term)(x:Inputs.Term, y: Outputs.Term) = \\n    sum(0 until x.length - 2)(i => t dot feature('skip, y(i), y(i+2)))\\n\\ndef newModel(t: Thetas.Term)(x: Inputs.Term)(y: Outputs.Term) = {\\n    biasTerms(t)(x, y) + wordTerms(t)(x, y) + pairTerms(t)(x, y) + skipTerms(t)(x, y)\\n} subjectTo (y.length === x.length) argmaxBy maxProduct\\n\\nval newTheta = learn(Thetas){ t => \\n    perceptron(train.toConst)(Outputs)(newModel(t))\\n} using adaGrad\\n\\nval newResult = argmax(Outputs){ newModel(thetaStar.toConst)(Inputs.Const(test))}.evalResult()\\n\"]"
      },
      "outputFormat" : "<div class=\"string-result\"><span class=\"label label-danger\">Error!</span>\n<pre class=\"error\"><console>:71: error: not found: value MaxProductParameters\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                       ^\n<console>:71: error: not found: value iterations\n       implicit val maxProductParams = MaxProductParameters(iterations = 1)\n                                                            ^\n<console>:84: error: could not find implicit value for parameter params: ml.wolfe.term.BPParameters\n       } subjectTo (y.length === x.length) argmaxBy maxProduct\n                                                    ^\n</console></console></console></pre></div>"
    }
  }, {
    "id" : 8,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "",
      "extraFields" : { },
      "outputFormat" : ""
    }
  } ],
  "config" : { }
}
